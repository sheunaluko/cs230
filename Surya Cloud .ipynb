{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util as u\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Activation\n",
    "import matplotlib.pyplot as plt\n",
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/vbookshelf/keras-iou-metric-implemented-without-tensor-drama\n",
    "\n",
    "def convert_to_iou_format(y) : \n",
    "    \"\"\"  \n",
    "    Will convert from [x_min, y_min, x_max, y_max] to [x, y, width, height] \n",
    "    \"\"\"\n",
    "    return np.array([ y[0,0] , y[0,1] , y[0,2]-y[0,0] , y[0,3]-y[0,1] ] ,ndmin=2) \n",
    "\n",
    "\n",
    "def calculate_iou(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input:\n",
    "    Keras provides the input as numpy arrays with shape (batch_size, num_columns).\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- first box, numpy array with format [x, y, width, height, conf_score]\n",
    "    y_pred -- second box, numpy array with format [x, y, width, height, conf_score]\n",
    "    x any y are the coordinates of the top left corner of each box.\n",
    "    \n",
    "    Output: IoU of type float32. (This is a ratio. Max is 1. Min is 0.)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for i in range(0,y_true.shape[0]):\n",
    "    \n",
    "        # set the types so we are sure what type we are using\n",
    "        y_true = convert_to_iou_format(y_true.astype(np.float32))\n",
    "       \n",
    "        y_pred = convert_to_iou_format(y_pred.astype(np.float32))   \n",
    "\n",
    "\n",
    "        # boxTrue\n",
    "        x_boxTrue_tleft = y_true[0,0]  # numpy index selection\n",
    "        y_boxTrue_tleft = y_true[0,1]\n",
    "        boxTrue_width = y_true[0,2]\n",
    "        boxTrue_height = y_true[0,3]\n",
    "        area_boxTrue = (boxTrue_width * boxTrue_height)\n",
    "\n",
    "        # boxPred\n",
    "        x_boxPred_tleft = y_pred[0,0]\n",
    "        y_boxPred_tleft = y_pred[0,1]\n",
    "        boxPred_width = y_pred[0,2]\n",
    "        boxPred_height = y_pred[0,3]\n",
    "        area_boxPred = (boxPred_width * boxPred_height)\n",
    "\n",
    "\n",
    "        # calculate the bottom right coordinates for boxTrue and boxPred\n",
    "\n",
    "        # boxTrue\n",
    "        x_boxTrue_br = x_boxTrue_tleft + boxTrue_width\n",
    "        y_boxTrue_br = y_boxTrue_tleft + boxTrue_height # Version 2 revision\n",
    "\n",
    "        # boxPred\n",
    "        x_boxPred_br = x_boxPred_tleft + boxPred_width\n",
    "        y_boxPred_br = y_boxPred_tleft + boxPred_height # Version 2 revision\n",
    "\n",
    "\n",
    "        # calculate the top left and bottom right coordinates for the intersection box, boxInt\n",
    "\n",
    "        # boxInt - top left coords\n",
    "        x_boxInt_tleft = np.max([x_boxTrue_tleft,x_boxPred_tleft])\n",
    "        y_boxInt_tleft = np.max([y_boxTrue_tleft,y_boxPred_tleft]) # Version 2 revision\n",
    "\n",
    "        # boxInt - bottom right coords\n",
    "        x_boxInt_br = np.min([x_boxTrue_br,x_boxPred_br])\n",
    "        y_boxInt_br = np.min([y_boxTrue_br,y_boxPred_br]) \n",
    "\n",
    "        # Calculate the area of boxInt, i.e. the area of the intersection \n",
    "        # between boxTrue and boxPred.\n",
    "        # The np.max() function forces the intersection area to 0 if the boxes don't overlap.\n",
    "        \n",
    "        \n",
    "        # Version 2 revision\n",
    "        area_of_intersection = \\\n",
    "        np.max([0,(x_boxInt_br - x_boxInt_tleft)]) * np.max([0,(y_boxInt_br - y_boxInt_tleft)])\n",
    "\n",
    "        iou = area_of_intersection / ((area_boxTrue + area_boxPred) - area_of_intersection)\n",
    "\n",
    "\n",
    "        # This must match the type used in py_func\n",
    "        iou = iou.astype(np.float32)\n",
    "        \n",
    "        # append the result to a list at the end of each loop\n",
    "        results.append(iou)\n",
    "    \n",
    "    # return the mean IoU score for the batch\n",
    "    return np.mean(results)\n",
    "\n",
    "\n",
    "def IoU(y_true, y_pred):\n",
    "    \n",
    "    # Note: the type float32 is very important. It must be the same type as the output from\n",
    "    # the python function above or you too may spend many late night hours \n",
    "    # trying to debug and almost give up.\n",
    "    \n",
    "    iou = tf.py_func(calculate_iou, [y_true, y_pred], tf.float32)\n",
    "\n",
    "    return iou "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/liver_train_part_1_xs.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-153a264852d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m39\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m39\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~tf/notebooks/util.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mxs_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfbase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"xs.npy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0mys_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfbase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"ys.npy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/liver_train_part_1_xs.npy'"
     ]
    }
   ],
   "source": [
    "xs,ys = u.get_dataset()\n",
    "X_train  = xs[:30]\n",
    "Y_train = ys[:30]; Y_train = Y_train.reshape(30,4)/512\n",
    "X_test = xs[30:39]\n",
    "Y_test = ys[30:39]; Y_test = Y_test.reshape(9,4)/512\n",
    "\n",
    "#set params\n",
    "batch_size=1\n",
    "num_epochs=300\n",
    "model_name=\"v0_\" + str(num_epochs) + \"e_b\" + str(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Conv2D(10, kernel_size=11, input_shape=(512, 512, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(10, kernel_size=11))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#pool\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(10, kernel_size=11))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(10, kernel_size=11))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#pool \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4, activation = None))\n",
    "\n",
    "\n",
    "#model.add(Dense(4, activation = \"sigmoid\", kernel_initializer=keras.initializers.RandomNormal(mean=0,stddev=0.05)))\n",
    "\n",
    "# https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-42b7e104e9f2>:99: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999), loss='mean_squared_error',metrics=[IoU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5ecb5f4a6d23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "h = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=batch_size, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = h.history['loss']\n",
    "test_loss  = h.history['val_loss']\n",
    "epoch_count = range(1, len(train_loss) + 1)\n",
    "\n",
    "plt.plot(epoch_count, train_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([0,0.2])\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
